# DDNN_ILOH
The repository for the NASA Illinois-Ohio River Basin project, modeling discharge and water temperature simoultaneously and then testing the T/Q hypothesis for drivers of algae. 

## `Functions_Paths.R`
This script centralizes all core file paths, directory setup, and shared helper functions for the project. It defines the base data directories (e.g., `data/`, `shapes/`, `nhdplus/`, `daily_drivers/`), ensures they exist, and provides utilities for safely writing geospatial outputs (like GeoPackages) and retrieving NLDI basins with error handling. It also loads the main package stack (sf, dplyr, nhdplusTools, dataRetrieval, tidyverse, etc.) so that downstream scripts can simply `source("Functions_Paths.R")` to inherit a consistent environment and path structure.

### `Boundaries.py`
This script initializes the spatial domain for the project by downloading and building watershed boundary shapefiles using the `pynhd` WaterData service. It queries the WBD HUC2 dataset (`wbd02`) to retrieve the Ohio River Basin (HUC2 = 05) and the WBD HUC4 dataset (`wbd04`) to retrieve the Illinois River Basin (HUC4 = 0712), saving them as `data/shapes/ohio_river_basin.shp` and `data/shapes/illinois_river_basin.shp`, respectively. It then merges both into a unified basin polygon, dissolving boundaries as needed, and writes the combined extent to `data/shapes/ohio_illinois_basin.shp`. These shapefiles serve as the upstream area-of-interest masks for all subsequent NHDPlus, GridMET, and monitoring-location extraction steps in the R and Python workflows.

## `Streamflow.Rmd`
This R Markdown script retrieves and cleans daily streamflow records for all USGS gages that have been snapped to NHDPlus COMIDs in the Illinois River Basin. Using the `sites_with_comid.shp` layer produced by `catchments.Rmd`, it queries NWIS daily values for parameter 00060 (streamflow), standardizes column names, converts flow from cubic feet per second to cubic meters per second, and joins each time series to its corresponding COMID. The resulting dataset is saved as `data/daily_drivers/q_obs.parquet`, and the script includes basic quality-control visualizations of data gaps and streamflow distributions to check for missingness and unit sanity.


## `Catchments.Rmd`
This R Markdown workflow builds the core hydrologic geospatial layer for the Illinois River Basin. Using the shared paths from `Functions_Paths.R`, it pulls NHDPlus flowlines and catchments for the basin AOI, checks for routing issues (orphan COMIDs), and saves cleaned flowlines and catchments as GeoPackages. It then identifies candidate USGS sites with discharge, temperature, and chlorophyll-a data, snaps them to the nearest flowlines, writes the site layer to disk, and finally delineates full upstream basins for all catchment COMIDs using NLDI, producing a basin dataset that can be used in subsequent modeling and driver-generation scripts.

## `Meteo.Rmd`
This R Markdown script downloads and aggregates daily meteorological drivers from GridMET for both NHDPlus catchments and their corresponding upstream basins in the Illinois River Basin. Using shared paths and helper functions from `Functions_Paths.R`, it reads the catchment and basin geometries, retrieves variables such as precipitation (pr), temperature (tmmx, tmmn), solar radiation (srad), wind speed (vs), vapor pressure deficit (vpd), specific humidity (sph), and relative humidity (rmin, rmax), and performs polygon-weighted spatial averaging with `exactextractr`. It writes per-variable daily CSV files to `data/meteo/` and combines all catchment- and basin-scale drivers into a single, wide daily table saved as `data/daily_drivers/drivers_daily_joined.feather`, which serves as the core meteorological input set for downstream modeling.

## `PET.Rmd`
This R Markdown script computes daily potential evapotranspiration (PET) for each COMID using the Hargreaves method, based on the merged meteorological drivers produced by `meteo.Rmd`. After loading `drivers_daily_joined.feather` and catchment geometries via `Functions_Paths.R`, it derives day-of-year (DOY) and catchment centroids to obtain latitude, then uses a shared `compute_Ra()` helper to estimate extraterrestrial radiation (Ra) and calculate catchment- and basin-scale PET fields (PET and `bsn_PET`). The script also augments the drivers with DOY sine and cosine terms for seasonal encoding and writes the enriched dataset to `data/daily_drivers/drivers_daily_joined_PET.feather`, ready for use in PGDL and other modeling workflows.

## `Hydro.Rmd`
This script assembles the final hydrologic node and edge datasets used for graph-based and deep learning models. It merges the PET-augmented meteorological drivers from `drivers_daily_joined_PET.feather` with the observed streamflow dataset `q_obs.parquet`, then joins catchment attributes (area) from `catchments.gpkg` to compute discharge depth in millimeters per day (`q_mm_day`). It further attaches hydraulic attributes from `flowlines.gpkg` (such as slope, length, and stream order) and builds a routed edge list using `fromnode` and `tonode`. The final outputs—`data/daily_drivers/hydro_data.parquet` (node features) and `data/daily_drivers/edge_list.parquet` (network topology)—form the core hydrologic input tables for your downstream GNN/LSTM modeling.

## `DDNN_QT_modeling.py`
This script trains a deep dynamic neural network (DDNN) that jointly predicts streamflow and water temperature across the Illinois River Basin river network using the preprocessed node and edge data products from the R pipeline. It ingests `hydro_temp_data.parquet` and `edge_list.parquet`, builds a COMID-indexed graph, and assembles dense spatiotemporal tensors where features are organized as `[time, node, feature]` and targets as `[time, node, {Q, T}]`. The model uses a 7-day sliding lookback window over all nodes, a calendar-based train–test split (`train < 2025-01-01`, `test ≥ 2025-01-01`), and MinMax scaling fit on the training period only. Dynamic predictors include meteorological drivers (e.g., `pr`, `srad`, `vs`, `vpd`, `sph`, `tmax_c`, `tmin_c`, `tmean_c`, `rmin`, `rmax`, `Ra`, `bsn_pr`) and seasonal terms (`DOY_sin`, `DOY_cos`), while static attributes (e.g., `areasqkm`, `slope`, `lengthkm`, `streamorde`) are automatically detected as COMID-invariant and appended to the feature set. The script preserves an explicit in-situ availability mask for water temperature so that missing temperature observations do not leak into the loss.

The core architecture is a multi-task GraphLSTM–GAT model: an LSTM ingests the per-node lookback sequence, compresses each node’s recent history into an embedding, and two stacked `GATConv` layers propagate information along the routed river network defined by `edge_list.parquet`. A shared linear head outputs two targets per node and time step: discharge (`q_m3s_obs`) and water temperature (`water_temp_C`) in scaled space. Training uses a mixed loss that combines a 1-NSE term for discharge and an MSE term for temperature (masked to locations with in-situ data), with user-defined task weights and early stopping controlled by validation loss and a `ReduceLROnPlateau` scheduler. After training, the script restores the best model, inverts the scaling to physical units, computes basin-wide performance metrics (NSE, RMSE, MAE) for both Q and T, and generates diagnostic plots, including a hydrograph and temperature time series for a target COMID and observed-versus-predicted scatter plots across all test nodes and timesteps. Finally, it saves the trained model weights and the fitted feature/target scalers to the `models/` directory for downstream inference or sensitivity analysis.
